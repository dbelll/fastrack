Today's Goals


Must do:

	Profile kernels


	Use twice as many threads in the learn kernel to speed up wgt copying.  The threads beyond
	dc_board_size then do nothing during learning.
	
	Add a parameter to parallel benchmark to specify the number of simultaneous threads
	
	Add an alternative benchmark of playing all the opponents (with learning off) - run this in parallel
	
	Create fixed baseline that shows good learning
	
	Within on learning session, allow multiple episodes of learning against opponents in parallel and then reducing the results,
		First, modify learn_kernel to either reset the stats, or read them from global memory and add them.
		
	Test GPUs random move generator
	implement random warm-up on GPU

	Review code for memory leaks

	build a program to test agents on set board positions
	
	put dc_best_opponents back to constant memory
	
	Fix standings spreadsheet to accomodate benchmark frequency
	
	Use the macros to get values from AGENT data
		
	Reduce the number of arguments by storing the pointer to AGENT *agGPU in constant memory and
	calculating the other pointers from it.
	
>>>>>>	On GPU - add multiple, simultaneous learning for each agent with sharing of results.
		Learn vs. each opponent simultaneously, storing the change in weights to global memory
		Calculate total change in weights accross all opponents and update agents weights with the total change
		
		?? Divide the 
		
	Compete against best agents from previous _2_ rounds
	
	Replicate the best agents with changes to alpha and/or lambda.



Todo's

Add ability to have varying num_hidden by agent



Processing

	init agents
	
	main loop
	
		learning session
			determine parameters for this learning session
			loop through all opponents
				learn against opponent for one episode
			next opponent	
		
		evaluate agents
			report stats
			replicate/vary
			
	repeat main loop for total session count


GPU Code
	check
	optimize
